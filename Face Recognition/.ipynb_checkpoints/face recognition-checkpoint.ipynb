{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb81266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os,numpy as np, cv2 , tensorflow as tf,time\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0d379",
   "metadata": {},
   "source": [
    "# encoding the known faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00d2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_faces_dir = \"static/data/known/\"\n",
    "def get_encoded_faces(known_faces_dir):\n",
    "    encoded = {}\n",
    "    for name in os.listdir(f\"{known_faces_dir}\"):\n",
    "        for filename in os.listdir(f\"{known_faces_dir}/{name}\"):\n",
    "            face = face_recognition.load_image_file(f\"{known_faces_dir}/{name}/{filename}\")\n",
    "            face_encodings = face_recognition.face_encodings(face)[0]\n",
    "            encoded[name.split(\".\")[0]] = face_encodings\n",
    "    return encoded;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f745455",
   "metadata": {},
   "source": [
    "# => detect the face on images \n",
    "# - draw the bounding box around the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec34a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectOnImage(imagePath):\n",
    "#     read the image for detecting\n",
    "    image = cv2.imread(f\"{imagePath}\",1)\n",
    "#   recognition on known faces\n",
    "    faces = get_encoded_faces(known_faces_dir)\n",
    "    faces_encoded = list(faces.values())\n",
    "    known_face_names = list(faces.keys())\n",
    "    colorsList = np.random.uniform(low=0,high=255, size = (len(known_face_names),3))\n",
    "#     fetch face features\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    face_encodings = face_recognition.face_encodings(image,face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "#         compare the known faces and the new image\n",
    "        matches = face_recognition.compare_faces(faces_encoded,face_encoding)\n",
    "        name = 'unknown'\n",
    "        color=(0,255,0);\n",
    "#         count the distance between the known faces and unknown face(new image)\n",
    "        faces_distances  = face_recognition.face_distance(faces_encoded,face_encoding) \n",
    "        best_match_index = np.argmin(faces_distances)\n",
    "#     define the name of face if is a known face with a random color\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            color = colorsList[best_match_index]\n",
    "        face_names.append(name)\n",
    "        #     Draw the Bounding Box around the face with label\n",
    "        for (top,right,bottom,left), name in zip(face_locations,face_names):            \n",
    "            cv2.rectangle(image,(left-20,top-20),(right+20,bottom+20),color,2)\n",
    "            cv2.putText(image, str(name), (left-20, top-25), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "            cv2.imwrite('./static/images/',image)\n",
    "#   display the final image after drawing the bounding box\n",
    "#     cv2.imshow(\"result:\",image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9842e9",
   "metadata": {},
   "source": [
    "# test on new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db448b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x000001E49FBC4470>, None, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14592/3187618961.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/test/kr.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/test/img2.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdetectOnImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# cv2.imshow(\"result:\",img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# cv2.waitKey(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14592/435405726.py\u001b[0m in \u001b[0;36mdetectOnImage\u001b[1;34m(imagePath)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcolorsList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknown_face_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     fetch face features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mface_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mface_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x000001E49FBC4470>, None, 1"
     ]
    }
   ],
   "source": [
    "img1 = \"data/test/kr.jpg\"\n",
    "img2 = \"data/test/img2.jpg\"\n",
    "detectOnImage(img1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117703f",
   "metadata": {},
   "source": [
    "# detection the faces on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7b2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectOnVideo():\n",
    "#     0 : for using the camera of my loptop\n",
    "#     you can replace 0 with  path of your video if you wanna use a specific video !!!\n",
    "        cap=cv2.VideoCapture(0)\n",
    "        if (cap.isOpened() == False):\n",
    "            print(\"Error in opning the video ....\")\n",
    "            return\n",
    "        (success, image)=cap.read()    \n",
    "        while success:\n",
    "            faces = get_encoded_faces()\n",
    "            faces_encoded = list(faces.values())\n",
    "            known_face_names = list(faces.keys())\n",
    "            \n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "            face_encodings = face_recognition.face_encodings(image,face_locations)\n",
    "            face_names=[]\n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(faces_encoded, face_encoding)\n",
    "                name='unknown'\n",
    "                color=(255,0,0)\n",
    "                face_distances=face_recognition.face_distance(faces_encoded,face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "                for (top,right,bottom,left),name in zip(face_locations, face_names):\n",
    "                    cv2.rectangle(image,(left-20,top-20),(right+20,bottom+20),color,2)\n",
    "                    cv2.putText(image,str(name),(left-20,top-25),cv2.FONT_HERSHEY_PLAIN,2,color,2)\n",
    "        \n",
    "            cv2.imshow(\"result\",image)\n",
    "            key= cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            (success,image)=cap.read()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e0a035c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectOnVideo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7d8fd",
   "metadata": {},
   "source": [
    "# run this app on web page using flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/',methods=['GET'])\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "@app.route('/',methods=['POST'])\n",
    "def FaceRecognition():\n",
    "        \n",
    "        img=request.files['image'];\n",
    "        image_path='./static/data/known/match/' + img.filename;\n",
    "        img.save(image_path);\n",
    "        \n",
    "        known_faces_dir='./static/data/known'\n",
    "        return render_template('index.html');\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predictonImage():\n",
    "    \n",
    "        img=request.files['image2'];\n",
    "        image_path='./static/images/' + img.filename;\n",
    "        img.save(image_path);\n",
    "        imageFinal = detectOnImage(image_path)\n",
    "        imageFinal.save('./static/images/'+imageFinal.filename)\n",
    "        return render_template('index.html',imgs=imageFinal);\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48651261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7880e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "631af202ec7c40e141c49d63cac6c8cb664469fed6e4d5ddc6436b49edc60500"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
